#!/usr/bin/env python3

from dotenv import load_dotenv, find_dotenv
load_dotenv(find_dotenv())

import shlex
from packaging import version as vcomp
import boto3
from munch import Munch
from urllib.request import urlopen, urlretrieve
import json
import os
import argparse
import toml
import sys
from datetime import date
import shutil
import tarfile
import re
import configparser
import lxml.etree as etree
from lxml.builder import ElementMaker
import glob
import github3 as github
import mimetypes
import subprocess
import textwrap
from string import Template
from pydpkg import Dpkg
from arpy import ArchiveFormatError

parser = argparse.ArgumentParser()
parser.add_argument('--bump', action='store_true')
parser.add_argument('--reload', action='store_true')
parser.add_argument('--rebuild', action='store_true')
args = parser.parse_args()
if args.reload or os.environ.get('REBUILD', '').strip() != '': args.rebuild = True

#### global data ####
with open('config.toml') as f:
  Config = toml.load(f, _dict=Munch)

ArchMap = {
  'i686': 'i386',
  'x86_64': 'amd64'
}

Clients = []
for section, values in Config.items():
  if 'name' in values and 'comment' in values: Clients.append(section)

def pluralize(d, singular):
  plural = singular + 's'
  assert not (singular in d and plural in d)
  if singular in d:
    d[plural] = d[singular]
    del d[singular]
  if plural in d and type(d[plural]) != list:
    d[plural] = [ d[plural] ]

with open('mimeinfo.toml') as f:
  MimeInfo = toml.load(f, _dict=Munch)
  for mi in MimeInfo.values():
    for singular in ['mimetype', 'extension']:
      plural = singular + 's'
      assert not (singular in mi and plural in mi)
      if singular in mi:
        mi[plural] = mi[singular]
        del mi[singular]
      if plural in mi and type(mi[plural]) != list:
        mi[plural] = [ mi[plural] ]
      
    if 'extensions' in mi:
      mi['extensions'] = [ext[1:] if ext[0] == '.' else ext for ext in mi['extensions']]

ESR = []
for dep in os.popen('apt-cache depends firefox-esr').read().split('\n'):
  dep = dep.strip()
  if not dep.startswith('Depends:'): continue
  dep = dep.split(':')[1].strip()
  if dep != 'lsb-release': # why should it need this?
    ESR.append(dep)

#### convenience functions ####

class Repository:
  def __init__(self):
    self.rebuild = 'Packages' not in self._assets # deleting 'Packages' forces re-uploading of everything
    if self.rebuild:
      for asset in self._assets.values():
        self.delete(asset)
      self._assets = {}

  def unchanged(self):
    published = set([asset for asset in self._assets.keys() if asset.endswith('.deb')])
    available = set([os.path.basename(deb.deb) for deb in Deb.all()])
    return published == available

class GitHub(Repository):
  def __init__(self, config):
    self.service = 'github'
    self.url = f'https://github.com/{config.repo}/releases/download/{config.release}'

    gh = github.GitHub(token=os.getenv('GITHUB_TOKEN'), session=session.GitHubSession(default_read_timeout=60))
    repo = gh.repository(*config.repo.split('/'))

    self._release = repo.release_from_tag(config.release)
    self._assets = { asset.name: asset for asset in self._release.assets() }

    super().__init__()

  def delete(self, asset):
    asset.delete()

  def get(self, name):
    if not name.endswith('.deb'): return False

    asset = self._assets.get(os.path.basename(name))
    if asset:
      os.makedirs(os.path.dirname(name), exist_ok=True)
      #urlretrieve(asset.download_url, name)
      run(f'curl -s -L -o {shlex.quote(name)} {shlex.quote(asset.download_url)}')
      return True
    return False

  def publish(self):
    print(f'\n## publishing repo to github')
    published = []
    for asset in self._release.assets():
      if not os.path.exists(f'repo/{asset.name}'):
        print('  deleting obsolete asset:', asset.name)
        asset.delete()
      elif asset.name.endswith('.deb') and not args.rebuild:
        published.append(asset.name)
      else:
        print('  refreshing asset:', asset.name)
        asset.delete()

    for asset in sorted(glob.glob('repo/*')):
      if os.path.basename(asset) in published: continue

      content_type = mimetypes.guess_type(asset)[0] or 'application/octet-stream'
      print(f'  uploading {asset} ({content_type})')
      with open(asset, 'rb') as f:
        self._release.upload_asset(
          asset=f,
          name=os.path.basename(asset),
          content_type=content_type
        )

class S3:
  def __init__(self, config):
    self.service = 's3'
    self.url = f'https://{config.bucket}.s3.{config.region}.amazonaws.com'

    s3 = boto3.resource('s3')
    self._bucket = s3.Bucket(name=config.bucket)
    self._assets = { asset.key: asset for asset in self.bucket.objects.all() }

    super().__init__()

  def delete(self, asset):
    self._bucket.delete_key(asset)
    
  def get(self, name):
    if not name.endswith('.deb'): return False

    try:
      for asset in self.bucket.objects.all():
        if os.path.basename(asset.key) == os.path.basename(name):
          self.bucket.download_file(os.path.basename(name), name)
          return True
    except:
      print('  error: could not get {os.path.basename(name)}')
      if os.path.exists(name): os.remove(name)

    return False

  def publish(self):
    print(f'\n## publishing repo to S3 bucket')
    published = []
    for asset in self.bucket.objects.all():
      if not os.path.exists(f'repo/{asset.key}'):
        print('  deleting obsolete asset:', asset.key)
        self.bucket.delete_key(asset)
      elif asset.key.endswith('.deb') and not args.rebuild:
        published.append(asset.key)
      else:
        print('  refreshing asset:', asset.key)

    for asset in sorted(glob.glob('repo/*')):
      if os.path.basename(asset) in published: continue

      content_type = mimetypes.guess_type(asset)[0] or 'application/octet-stream'
      print(f'  uploading {asset} ({content_type})')
      self.bucket.upload_file(asset, os.path.basename(asset))

branch = os.environ.get('GITHUB_REF', '')
branch = branch.split('/')[-1] if branch.startswith('refs/heads/') else None
Repo = None
print(f'\n## branch = {branch}')
if branch and branch in Config:
  for hosting, config in [(h.lower(), data) for h, data in Config[branch].items() if h.lower() in ('github', 's3')]:
    if hosting == 'github':
      print('\n## publish target: Github release')
      Repo = GitHub(config)
    elif hosting == 's3':
      print('\n## publish target: S3 bucket')
      Repo = S3(config)
    break

if not Repo:
  print(f'  no repo found for {branch}')

def run(cmd):
  print('  $', cmd)

  try:
   print(textwrap.indent(subprocess.check_output(cmd, shell=True).decode('utf-8'), '    '))
  except subprocess.CalledProcessError as e:
    print(textwrap.indent(e.output.decode('utf-8'), '    '))
    sys.exit(1)

class Open():
  def __init__(self, path, mode='r', fmode=None):
    if 'w' in mode or 'a' in mode: os.makedirs(os.path.dirname(path), exist_ok=True)
    self.path = path
    self.mode = fmode
    self.f = open(path, mode)
  def __enter__(self):
    return self.f
  def __exit__(self, exc_type, exc_value, exc_traceback):
    self.f.close()
    if self.mode is not None:
      os.chmod(self.path, self.mode)

def load(url,parse_json=False):
  response = urlopen(url).read()
  if type(response) is bytes: response = response.decode('utf-8')
  if parse_json:
    return json.loads(response, object_hook=Munch.fromDict)
  else:
    return response

class Version:
  def __init__(self, deb, *args):
    self.deb  = deb
  def __lt__(self, other):
    if self.deb.client == other.deb.client:
      return vcomp.parse(self.deb.version.replace('m', '.')) < vcomp.parse(other.deb.version.replace('m', '.'))
    else:
      return self.deb.client < other.deb.client
  def __gt__(self, other):
    if self.deb.client == other.deb.client:
      return vcomp.parse(self.deb.version.replace('m', '.')) > vcomp.parse(other.deb.version.replace('m', '.'))
    else:
      return self.deb.client > other.deb.client
  def __eq__(self, other):
    return self.deb.client == other.deb.client and vcomp.parse(self.deb.version.replace('m', '.')) == vcomp.parse(other.deb.version.replace('m', '.'))
  def __le__(self, other):
    if self.deb.client == other.deb.client:
      return vcomp.parse(self.deb.version.replace('m', '.')) <= vcomp.parse(other.deb.version.replace('m', '.'))
    else:
      return self.deb.client <= other.deb.client
  def __ge__(self, other):
    if self.deb.client == other.deb.client:
      return vcomp.parse(self.deb.version.replace('m', '.')) >= vcomp.parse(other.deb.version.replace('m', '.'))
    else:
      return self.deb.client >= other.deb.client
  def __ne__(self, other):
    return self.deb.client != other.deb.client and vcomp.parse(self.deb.version.replace('m', '.')) != vcomp.parse(other.deb.version.replace('m', '.'))

class Deb:
  __debs = []

  @classmethod
  def select(cls, version = None, client = None, arch=None, aptarch=None, beta=True):
    def equal(deb):
      return (version is None or version == deb.version) and (client is None or client == deb.client) and (arch is None or arch == deb.arch) and (aptarch is None or aptarch == deb.apt.arch) and (beta or not deb.beta)
    #print('version:', version, 'client:', client, 'arch:', arch, 'aptarch:', aptarch, 'beta:', beta)
    #for deb in cls.__debs:
    #  if equal(deb):
    #    print('== version:', deb.version, 'client:', deb.client, 'arch:', deb.arch, 'aptarch:', deb.apt.arch, 'beta:', deb.beta)
    #  else:
    #    print('!=',
    #      'version:', deb.version, 
    #      'client:', deb.client, 
    #      'arch:', deb.arch,
    #      'aptarch:', deb.apt.arch,
    #      'beta:', deb.beta
    #    )

    return sorted([deb for deb in cls.__debs if equal(deb)], key=Version)

  @classmethod
  def all(cls):
    return cls.select()

  @classmethod
  def rebuilt(cls):
    return any(deb for deb in cls.__debs if deb.rebuilt)

  def __init__(self, client, version, arch):
    Deb.__debs.append(self)

    self.rebuilt = False

    self.client = client
    self.version = version
    self.arch = arch
    self.beta = version.startswith('beta-')

    # set download URL
    self.url = {
      'zotero':       f'https://www.zotero.org/download/client/dl?channel=release&platform=linux-{arch}&version={version}',
      'zotero-beta':  f'https://www.zotero.org/download/client/dl?channel=beta&platform=linux-{arch}',

      'jurism':       f'https://github.com/Juris-M/assets/releases/download/client%2Frelease%2F{version}/Jurism-{version}_linux-{arch}.tar.bz2',
      'jurism-beta':  f'https://our.law.nagoya-u.ac.jp/jurism/dl?channel=beta&platform=linux-{arch}',
    }[f'{self.client}{"-beta" if self.beta else ""}']

  @property
  def deb(self):
    return f'repo/{self.client}{self.apt.postfix}_{self.apt.version}{self.apt.patch}_{self.apt.arch}.deb'

  @property
  def tarball(self):
    return os.path.join(self.client, self.arch, self.version + '.tar.bz2')

  @property
  def apt(self):
    if self.beta:
      apt = Munch(
        postfix='-beta',
        version=self.version.replace('beta-', '').replace('-', '.'),
        patch='',
        arch=ArchMap[self.arch]
      )
    else:
      apt = Munch(
        postfix='',
        version=self.version,
        patch='',
        arch=ArchMap[self.arch]
      )
      if 'patch' in Config[self.client] and 'version' in Config[self.client].patch:
        apt.patch = '-' + str(Config[self.client].patch[self.version])
    return apt
    
  def build(self):
    if not 'patch' in Config[client]: Config[client].patch = Munch()

    print(f'\n## building {self.deb}')
    self.rebuilt = True

    exists = None
    if args.rebuild:
      print('  forced rebuild')
    elif os.path.exists(self.deb):
      exists = f'  {self.deb} already exists'
    elif Repo and Repo.get(self.deb):
      exists = f'  {self.deb} re-fetched'
    if exists:
      try:
        # for some bloody reason Github frequently hands us a JSON description of the asset rather than the asset itself
        Dpkg(self.deb).headers
        print(exists)
        return
      except ArchiveFormatError:
        print(exists + ', but is corrupted')
        if os.path.exists(self.deb): os.remove(self.deb)

    if not os.path.exists(self.tarball) or args.reload:
      os.makedirs(os.path.dirname(self.tarball), exist_ok=True)
      print('  downloading', self.tarball)
      urlretrieve(self.url, self.tarball)

    if os.path.exists('build'): shutil.rmtree('build')
    os.makedirs('build')
  
    print(f'  unpacking {self.tarball}')
    tar = tarfile.open(self.tarball)
    for member in tar.getmembers():
      if not member.isreg(): continue
      member.name = re.sub(r'^.+?\/', '', member.name) # strip leading directory
  
      if member.name in ['zotero.desktop', 'jurism.desktop', 'active-update.xml', 'precomplete', 'removed-files', 'updates', 'updates.xml']:
        continue
  
      tar.extract(member, f'build/usr/lib/{self.client}{self.apt.postfix}')
    tar.close()
  
    print(f'  disable auto-update')
    with Open(f'build/usr/lib/{self.client}{self.apt.postfix}/defaults/pref/local-settings.js', 'a') as ls, Open(f'build/usr/lib/{self.client}{self.apt.postfix}/mozilla.cfg', 'a') as cfg:
      # enable mozilla.cfg
      if ls.tell() != 0: print('', file=ls)
      print('pref("general.config.obscure_value", 0); // only needed if you do not want to obscure the content with ROT-13', file=ls)
      print('pref("general.config.filename", "mozilla.cfg");', file=ls)

      # disable auto-update
      if cfg.tell() == 0:
        print('//', file=cfg)
      else:
        print('', file=cfg)
      print('lockPref("app.update.enabled", false);', file=cfg)
      print('lockPref("app.update.auto", false);', file=cfg)
  
    print(f'  write launcher entry')
    with Open(f'build/usr/share/applications/{self.client}{self.apt.postfix}.desktop', 'w') as f:
      desktop = configparser.RawConfigParser()
      desktop.add_section('Desktop Entry')
      desktop.optionxform=str
      desktop.set('Desktop Entry', 'Name', Config[client].name + self.apt.postfix.replace('-', ' '))
      desktop.set('Desktop Entry', 'Comment', Config[client].comment)
      desktop.set('Desktop Entry', 'Exec', f'/usr/lib/{self.client}{self.apt.postfix}/{self.client} --url %u')
      desktop.set('Desktop Entry', 'Icon', f'/usr/lib/{self.client}{self.apt.postfix}/chrome/icons/default/default256.png')
      desktop.set('Desktop Entry', 'Type', 'Application')
      desktop.set('Desktop Entry', 'Categories', Config[client].categories)
      desktop.set('Desktop Entry', 'StartupNotify', 'true')
      desktop.set('Desktop Entry', 'MimeType', ';'.join([mt for mi in MimeInfo.values() for mt in mi.mimetypes]))
      desktop.write(f, space_around_delimiters=False)

    print(f'  update mime info')
    with Open(f'build/usr/share/mime/packages/{self.client}{self.apt.postfix}.xml', 'wb') as f:
      E = ElementMaker(
        namespace='http://www.freedesktop.org/standards/shared-mime-info',
        nsmap={
          None : 'http://www.freedesktop.org/standards/shared-mime-info',
          'xml': 'http://www.w3.org/XML/1998/namespace',
        }
      )
      _mimetypes = []
      MIMETYPE = getattr(E, 'mime-type')
      MIMEINFO = getattr(E, 'mime-info')
      for name, mi in MimeInfo.items():
        if not 'extensions' in mi: continue

        children = [E.comment(name)]
        for k, v in mi.items():
          if len(k) == 2:
            children.append(E.comment(v, **{'{http://www.w3.org/XML/1998/namespace}lang': k}))
        for ext in mi.get('extensions', []):
          children.append(E.glob(pattern=f'*.{ext}'))
        for mt in mi.mimetypes[1:]:
          children.append(E.alias(type=mt))
        _mimetypes.append(MIMETYPE(*children, type=mi.mimetypes[0]))
      f.write(etree.tostring(MIMEINFO(*_mimetypes), pretty_print=True, xml_declaration=True, encoding='utf-8'))

    print(f'  write build control file')
    with Open('build/DEBIAN/control', 'w') as f:
      dependencies = ', '.join(sorted(list(set(Config[client].dependencies + ESR))))
      print(f'Package: {self.client}{self.apt.postfix}', file=f)
      print(f'Architecture: {self.apt.arch}', file=f)
      print(f'Depends: {dependencies}'.strip(), file=f)
      print(f'Maintainer: {Config.maintainer.email}', file=f)
      print(f'Section: {Config[client].section}', file=f)
      print('Priority: optional', file=f)
      print(f'Version: {self.apt.version}{self.apt.patch}', file=f)
      print(f'Description: {Config[self.client].description}', file=f)

    os.makedirs('build/usr/local/bin')
    os.symlink(f'/usr/lib/{self.client}{self.apt.postfix}/{self.client}', f'build/usr/local/bin/{self.client}{self.apt.postfix}')

    os.makedirs('repo', exist_ok=True)
    run(f'fakeroot dpkg-deb --build -Zgzip build {self.deb}')
    run(f'dpkg-sig -k {Config.maintainer.gpgkey} --sign builder {self.deb}')

#### deb builder ####

# cleanup interrupted build
for deb in glob.glob('repo/*.deb.*'):
  os.remove(deb)

# gather .debs to build
for client in Clients:
  if client == 'zotero':
    versions = [release.version for release in load('https://www.zotero.org/download/client/manifests/release/updates-linux-x86_64.json', parse_json=True)]
  else:
    versions = []
    # jurism puts out new version in a frenzied burst -- only keep the last m-version
    for version in [release for release in load('https://github.com/Juris-M/assets/releases/download/client%2Freleases%2Fincrementals-linux/incrementals-release-linux').split('\n') if release != '']:
      if len(versions) == 0:
        versions.append(version)
      elif version.split('m')[0] == versions[-1].split('m')[0]:
        versions[-1] = version
      else:
        versions.append(version)
  versions.append(f'beta-{date.today().isoformat()}')

  for version in versions:
    for arch in ArchMap.keys():
      Deb(client, version, arch)

# cleanup leftover tarballs
for client in Clients:
  for tarball in glob.glob(f'{client}/*/*.tar.bz2'):
    arch = os.path.basename(os.path.dirname(tarball))
    version = os.path.basename(tarball).replace('.tar.bz2', '')
    if not any(deb for deb in Deb.select(client=client, version=version, arch=arch)):
      print('removing', tarball)
      os.remove(tarball)

# bump patch level
if args.bump:
  for client in Clients:
    debs = Debs.select(client=client, beta=False)
    if not 'patch' in Config[client]:
      Config[client].patch = Munch()
      Config[client].patch[debs[-1].version] = 0
    Config[client].patch[debs[-1].version] += 1
  with open('config.toml', 'w') as f:
    toml.dump(Config, f)

# build and download as needed

if not args.rebuild and Repo and Repo.unchanged():
  print('\n## repo up to date')
  sys.exit()
if Repo and Repo.rebuild: args.rebuild = True

for deb in Deb.all():
  deb.build()

# cleanup leftover .debs
for deb in glob.glob('repo/*.deb'):
  client, version, aptarch = os.path.splitext(os.path.basename(deb))[0].split('_')[:3]
  if client.endswith('-beta'):
    version = 'beta-' + version.replace('.', '-')
    client = client.replace('-beta', '')
  if not any(d for d in Deb.select(client=client, version=version, aptarch=aptarch)):
    if os.path.exists('repo/Packages'): os.remove('repo/Packages')
    print('removing', deb)
    os.remove(deb)

if Deb.rebuilt or not os.path.exists('repo/Packages'):
  print(f'\n## preparing repo')
  run(f'gpg --armor --export {Config.maintainer.gpgkey} > repo/deb.gpg.key')
  run(f'cd repo && apt-ftparchive packages . > Packages')
  run(f'bzip2 -kf repo/Packages')
  run(f'cd repo && apt-ftparchive release . > Release')
  run(f'gpg --yes -abs -u {Config.maintainer.gpgkey} -o repo/Release.gpg --digest-algo sha256 repo/Release')
  run(f'gpg --yes -abs -u {Config.maintainer.gpgkey} --clearsign -o repo/InRelease --digest-algo sha256 repo/Release')

  if Repo:
    with open('repo/install.sh', 'w') as install, open('install.sh') as tmpl:
      install.write(Template(tmpl.read()).substitute(url=Repo.url))
  else:
    if os.path.exists('repo/install.sh'): os.remove('repo/install.sh')

  if Repo:
    Repo.publish()
    print(f'::set-output name=url::{Repo.url}')
    print('::set-output name=rebuilt::true')
  else:
    print(f'\n## not publishing repo: no repo specified')
else:
  print(f'\n## not publishing repo: nothing rebuilt')
